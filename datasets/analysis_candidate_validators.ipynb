{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Candidate Validator Model Analysis\n",
        "\n",
        "Analyzing whether expensive reasoning tokens are necessary for the validator model.\n",
        "\n",
        "Compares:\n",
        "- Gemini 3 Flash with reasoning (current validator)\n",
        "- Gemini 3 Flash without reasoning\n",
        "- DeepSeek v3.2 with reasoning\n",
        "- DeepSeek v3.2 without reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 313 questions from data/candidate_validators_questions_fast_20260122_084427_20260122_095954.json\n"
          ]
        }
      ],
      "source": [
        "# Load the most recent results file\n",
        "# results_file = sorted(results_files)[-1] if results_files else None\n",
        "results_file = \"data/candidate_validators_questions_fast_20260122_084427_20260122_095954.json\"\n",
        "if results_file:\n",
        "    with open(results_file) as f:\n",
        "        results = json.load(f)\n",
        "    print(f\"Loaded {len(results)} questions from {results_file}\")\n",
        "else:\n",
        "    print(\"No results files found. Run evaluate_candidate_validator_models.py first.\")\n",
        "    results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models evaluated: ['gemini_thinking', 'gemini_no_thinking', 'deepseek_thinking', 'deepseek_no_thinking']\n"
          ]
        }
      ],
      "source": [
        "if results:\n",
        "    models = list(results[0][\"evaluations\"].keys())\n",
        "    print(f\"Models evaluated: {models}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agreement with Generator (Grok)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gemini_thinking          : 254/313 (81.2%) agree with generator\n",
            "gemini_no_thinking       : 219/313 (70.0%) agree with generator\n",
            "deepseek_thinking        : 242/313 (77.3%) agree with generator\n",
            "deepseek_no_thinking     : 262/313 (83.7%) agree with generator\n"
          ]
        }
      ],
      "source": [
        "if results:\n",
        "    for model in models:\n",
        "        agree = sum(1 for r in results \n",
        "                    if r[\"evaluations\"].get(model, {}).get(\"answer\") == r[\"generator_answer_idx\"])\n",
        "        pct = 100 * agree / len(results)\n",
        "        print(f\"{model:25s}: {agree}/{len(results)} ({pct:.1f}%) agree with generator\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agreement with Gemini Thinking (Current Validator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agreement with gemini_thinking:\n",
            "\n",
            "gemini_no_thinking       : 219/313 (70.0%)\n",
            "deepseek_thinking        : 247/313 (78.9%)\n",
            "deepseek_no_thinking     : 260/313 (83.1%)\n"
          ]
        }
      ],
      "source": [
        "if results and \"gemini_thinking\" in models:\n",
        "    reference_model = \"gemini_thinking\"\n",
        "    print(f\"Agreement with {reference_model}:\\n\")\n",
        "    \n",
        "    for model in models:\n",
        "        if model == reference_model:\n",
        "            continue\n",
        "        agree = sum(1 for r in results \n",
        "                    if r[\"evaluations\"].get(model, {}).get(\"answer\") == \n",
        "                       r[\"evaluations\"].get(reference_model, {}).get(\"answer\"))\n",
        "        pct = 100 * agree / len(results)\n",
        "        print(f\"{model:25s}: {agree}/{len(results)} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agreement with Gemini Thinking (Where GT Agrees with Generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cases where gemini_thinking agrees with generator: 254/313\n",
            "\n",
            "Agreement with gemini_thinking (filtered, excluding nulls):\n",
            "\n",
            "gemini_no_thinking       : 201/243 (82.7%) agree | 11 nulls (4.3%)\n",
            "deepseek_thinking        : 226/228 (99.1%) agree | 26 nulls (10.2%)\n",
            "deepseek_no_thinking     : 241/248 (97.2%) agree | 6 nulls (2.4%)\n"
          ]
        }
      ],
      "source": [
        "if results and \"gemini_thinking\" in models:\n",
        "    reference_model = \"gemini_thinking\"\n",
        "    \n",
        "    # Filter to cases where gemini_thinking agrees with generator\n",
        "    gt_agrees_with_gen = [r for r in results \n",
        "                          if r[\"evaluations\"].get(reference_model, {}).get(\"answer\") == r[\"generator_answer_idx\"]]\n",
        "    \n",
        "    print(f\"Cases where {reference_model} agrees with generator: {len(gt_agrees_with_gen)}/{len(results)}\\n\")\n",
        "    print(f\"Agreement with {reference_model} (filtered, excluding nulls):\\n\")\n",
        "    \n",
        "    for model in models:\n",
        "        if model == reference_model:\n",
        "            continue\n",
        "        \n",
        "        # Get reference answer (we know it's not null since it agreed with generator)\n",
        "        ref_not_null = [r for r in gt_agrees_with_gen \n",
        "                        if r[\"evaluations\"].get(reference_model, {}).get(\"answer\") is not None]\n",
        "        \n",
        "        # Count nulls for this model (where reference is not null)\n",
        "        model_nulls = sum(1 for r in ref_not_null \n",
        "                         if r[\"evaluations\"].get(model, {}).get(\"answer\") is None)\n",
        "        null_pct = 100 * model_nulls / len(ref_not_null) if ref_not_null else 0\n",
        "        \n",
        "        # Non-null cases for both models\n",
        "        valid_cases = [r for r in ref_not_null \n",
        "                       if r[\"evaluations\"].get(model, {}).get(\"answer\") is not None]\n",
        "        \n",
        "        # Agreement among valid (non-null) cases\n",
        "        agree = sum(1 for r in valid_cases \n",
        "                    if r[\"evaluations\"].get(model, {}).get(\"answer\") == \n",
        "                       r[\"evaluations\"].get(reference_model, {}).get(\"answer\"))\n",
        "        pct = 100 * agree / len(valid_cases) if valid_cases else 0\n",
        "        \n",
        "        print(f\"{model:25s}: {agree}/{len(valid_cases)} ({pct:.1f}%) agree | {model_nulls} nulls ({null_pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pairwise Agreement Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pairwise agreement (%):\n",
            "\n",
            "                      gemini_thinking  gemini_no_thinking  deepseek_thinking  deepseek_no_thinking\n",
            "gemini_thinking                 100.0                70.0               78.9                  83.1\n",
            "gemini_no_thinking               70.0               100.0               67.1                  69.6\n",
            "deepseek_thinking                78.9                67.1              100.0                  83.1\n",
            "deepseek_no_thinking             83.1                69.6               83.1                 100.0\n"
          ]
        }
      ],
      "source": [
        "if results:\n",
        "    agreement_matrix = {}\n",
        "    for m1 in models:\n",
        "        agreement_matrix[m1] = {}\n",
        "        for m2 in models:\n",
        "            agree = sum(1 for r in results \n",
        "                        if r[\"evaluations\"].get(m1, {}).get(\"answer\") == \n",
        "                           r[\"evaluations\"].get(m2, {}).get(\"answer\"))\n",
        "            agreement_matrix[m1][m2] = agree / len(results)\n",
        "    \n",
        "    df = pd.DataFrame(agreement_matrix).T * 100\n",
        "    print(\"Pairwise agreement (%):\\n\")\n",
        "    print(df.round(1).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cases Where Models Disagree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if results and \"gemini_thinking\" in models and \"gemini_no_thinking\" in models:\n",
        "#     disagree_cases = []\n",
        "#     for r in results:\n",
        "#         gt_ans = r[\"evaluations\"].get(\"gemini_thinking\", {}).get(\"answer\")\n",
        "#         no_think_ans = r[\"evaluations\"].get(\"gemini_no_thinking\", {}).get(\"answer\")\n",
        "#         if gt_ans != no_think_ans:\n",
        "#             disagree_cases.append({\n",
        "#                 \"idx\": r[\"idx\"],\n",
        "#                 \"level\": r[\"level\"],\n",
        "#                 \"subject\": r[\"subject\"],\n",
        "#                 \"generator\": r[\"generator_answer_idx\"],\n",
        "#                 \"gemini_thinking\": gt_ans,\n",
        "#                 \"gemini_no_thinking\": no_think_ans\n",
        "#             })\n",
        "    \n",
        "#     print(f\"Gemini thinking vs no-thinking disagree on {len(disagree_cases)} questions:\")\n",
        "#     if disagree_cases:\n",
        "#         df = pd.DataFrame(disagree_cases)\n",
        "#         print(df.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Agreement by Difficulty Level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agreement with generator by level:\n",
            "\n",
            "Level 1 (n=64):\n",
            "  gemini_thinking          : 81.2%\n",
            "  gemini_no_thinking       : 76.6%\n",
            "  deepseek_thinking        : 79.7%\n",
            "  deepseek_no_thinking     : 85.9%\n",
            "\n",
            "Level 2 (n=66):\n",
            "  gemini_thinking          : 81.8%\n",
            "  gemini_no_thinking       : 77.3%\n",
            "  deepseek_thinking        : 83.3%\n",
            "  deepseek_no_thinking     : 89.4%\n",
            "\n",
            "Level 3 (n=66):\n",
            "  gemini_thinking          : 89.4%\n",
            "  gemini_no_thinking       : 72.7%\n",
            "  deepseek_thinking        : 81.8%\n",
            "  deepseek_no_thinking     : 84.8%\n",
            "\n",
            "Level 4 (n=61):\n",
            "  gemini_thinking          : 78.7%\n",
            "  gemini_no_thinking       : 67.2%\n",
            "  deepseek_thinking        : 72.1%\n",
            "  deepseek_no_thinking     : 83.6%\n",
            "\n",
            "Level 5 (n=56):\n",
            "  gemini_thinking          : 73.2%\n",
            "  gemini_no_thinking       : 53.6%\n",
            "  deepseek_thinking        : 67.9%\n",
            "  deepseek_no_thinking     : 73.2%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if results:\n",
        "    levels = sorted(set(r[\"level\"] for r in results))\n",
        "    print(\"Agreement with generator by level:\\n\")\n",
        "    \n",
        "    for level in levels:\n",
        "        level_results = [r for r in results if r[\"level\"] == level]\n",
        "        print(f\"Level {level} (n={len(level_results)}):\")\n",
        "        for model in models:\n",
        "            agree = sum(1 for r in level_results \n",
        "                        if r[\"evaluations\"].get(model, {}).get(\"answer\") == r[\"generator_answer_idx\"])\n",
        "            pct = 100 * agree / len(level_results) if level_results else 0\n",
        "            print(f\"  {model:25s}: {pct:.1f}%\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Token Usage and Cost Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token usage and cost summary (n=313):\n",
            "\n",
            "gemini_thinking:\n",
            "  Prompt tokens:     120,411\n",
            "  Completion tokens: 1,623,383 (avg 5187/question)\n",
            "  Total tokens:      1,743,794\n",
            "  Cost per 1000:     $15.75\n",
            "\n",
            "gemini_no_thinking:\n",
            "  Prompt tokens:     115,074\n",
            "  Completion tokens: 327,393 (avg 1046/question)\n",
            "  Total tokens:      442,467\n",
            "  Cost per 1000:     $3.32\n",
            "\n",
            "deepseek_thinking:\n",
            "  Prompt tokens:     96,896\n",
            "  Completion tokens: 506,346 (avg 1618/question)\n",
            "  Total tokens:      603,242\n",
            "  Cost per 1000:     $0.89\n",
            "\n",
            "deepseek_no_thinking:\n",
            "  Prompt tokens:     112,267\n",
            "  Completion tokens: 373,765 (avg 1194/question)\n",
            "  Total tokens:      486,032\n",
            "  Cost per 1000:     $0.71\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if results:\n",
        "    usage_stats = defaultdict(lambda: {\"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0, \"cost\": 0.0})\n",
        "    \n",
        "    for r in results:\n",
        "        for model, eval_data in r[\"evaluations\"].items():\n",
        "            usage = eval_data.get(\"usage\", {})\n",
        "            usage_stats[model][\"prompt_tokens\"] += usage.get(\"prompt_tokens\", 0)\n",
        "            usage_stats[model][\"completion_tokens\"] += usage.get(\"completion_tokens\", 0)\n",
        "            usage_stats[model][\"total_tokens\"] += usage.get(\"total_tokens\", 0)\n",
        "            usage_stats[model][\"cost\"] += usage.get(\"cost\", 0) or 0\n",
        "    \n",
        "    print(f\"Token usage and cost summary (n={len(results)}):\\n\")\n",
        "    for model in models:\n",
        "        stats = usage_stats[model]\n",
        "        avg_completion = stats[\"completion_tokens\"] / len(results) if results else 0\n",
        "        cost_per_1k = 1000 * stats[\"cost\"] / len(results) if results else 0\n",
        "        print(f\"{model}:\")\n",
        "        print(f\"  Prompt tokens:     {stats['prompt_tokens']:,}\")\n",
        "        print(f\"  Completion tokens: {stats['completion_tokens']:,} (avg {avg_completion:.0f}/question)\")\n",
        "        print(f\"  Total tokens:      {stats['total_tokens']:,}\")\n",
        "        print(f\"  Cost per 1000:     ${cost_per_1k:.2f}\")\n",
        "        print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error counts by model:\n",
            "\n",
            "gemini_thinking          : 1 API errors, 22 parse failures\n",
            "gemini_no_thinking       : 1 API errors, 20 parse failures\n",
            "deepseek_thinking        : 45 API errors, 4 parse failures\n",
            "deepseek_no_thinking     : 6 API errors, 3 parse failures\n"
          ]
        }
      ],
      "source": [
        "if results:\n",
        "    print(\"Error counts by model:\\n\")\n",
        "    for model in models:\n",
        "        errors = sum(1 for r in results if \"error\" in r[\"evaluations\"].get(model, {}))\n",
        "        parse_failures = sum(1 for r in results \n",
        "                            if r[\"evaluations\"].get(model, {}).get(\"answer\") is None \n",
        "                            and \"error\" not in r[\"evaluations\"].get(model, {}))\n",
        "        print(f\"{model:25s}: {errors} API errors, {parse_failures} parse failures\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Recommendation Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "When gemini_thinking AGREES with generator (n=254):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cost per 1000</th>\n",
              "      <th>Agree %</th>\n",
              "      <th>Null %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gemini_thinking</th>\n",
              "      <td>$15.75</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini_no_thinking</th>\n",
              "      <td>$3.32</td>\n",
              "      <td>82.7</td>\n",
              "      <td>4.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_thinking</th>\n",
              "      <td>$0.89</td>\n",
              "      <td>99.1</td>\n",
              "      <td>10.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_no_thinking</th>\n",
              "      <td>$0.71</td>\n",
              "      <td>97.2</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Cost per 1000  Agree %  Null %\n",
              "gemini_thinking             $15.75    100.0     0.0\n",
              "gemini_no_thinking           $3.32     82.7     4.3\n",
              "deepseek_thinking            $0.89     99.1    10.2\n",
              "deepseek_no_thinking         $0.71     97.2     2.4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Agree % by level (where GT agrees with generator):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gemini_thinking</th>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini_no_thinking</th>\n",
              "      <td>88.5</td>\n",
              "      <td>88.2</td>\n",
              "      <td>85.5</td>\n",
              "      <td>79.2</td>\n",
              "      <td>67.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_thinking</th>\n",
              "      <td>95.9</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_no_thinking</th>\n",
              "      <td>98.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>94.8</td>\n",
              "      <td>95.7</td>\n",
              "      <td>97.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          1      2      3      4      5\n",
              "gemini_thinking       100.0  100.0  100.0  100.0  100.0\n",
              "gemini_no_thinking     88.5   88.2   85.5   79.2   67.6\n",
              "deepseek_thinking      95.9  100.0  100.0  100.0  100.0\n",
              "deepseek_no_thinking   98.0  100.0   94.8   95.7   97.4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Null % by level (where GT agrees with generator):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gemini_thinking</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini_no_thinking</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>6.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_thinking</th>\n",
              "      <td>5.8</td>\n",
              "      <td>3.7</td>\n",
              "      <td>10.2</td>\n",
              "      <td>16.7</td>\n",
              "      <td>17.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_no_thinking</th>\n",
              "      <td>1.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2.1</td>\n",
              "      <td>7.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        1    2     3     4     5\n",
              "gemini_thinking       0.0  0.0   0.0   0.0   0.0\n",
              "gemini_no_thinking    0.0  5.6   6.8   0.0   9.8\n",
              "deepseek_thinking     5.8  3.7  10.2  16.7  17.1\n",
              "deepseek_no_thinking  1.9  0.0   1.7   2.1   7.3"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Agree % by subject (where GT agrees with generator):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>algebra</th>\n",
              "      <th>counting_and_probability</th>\n",
              "      <th>geometry</th>\n",
              "      <th>intermediate_algebra</th>\n",
              "      <th>number_theory</th>\n",
              "      <th>prealgebra</th>\n",
              "      <th>precalculus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gemini_thinking</th>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini_no_thinking</th>\n",
              "      <td>88.9</td>\n",
              "      <td>76.9</td>\n",
              "      <td>78.6</td>\n",
              "      <td>73.3</td>\n",
              "      <td>82.9</td>\n",
              "      <td>95.3</td>\n",
              "      <td>76.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_thinking</th>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>97.5</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_no_thinking</th>\n",
              "      <td>100.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>89.3</td>\n",
              "      <td>93.3</td>\n",
              "      <td>97.5</td>\n",
              "      <td>97.7</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      algebra  counting_and_probability  geometry  \\\n",
              "gemini_thinking         100.0                     100.0     100.0   \n",
              "gemini_no_thinking       88.9                      76.9      78.6   \n",
              "deepseek_thinking       100.0                     100.0      96.0   \n",
              "deepseek_no_thinking    100.0                     100.0      89.3   \n",
              "\n",
              "                      intermediate_algebra  number_theory  prealgebra  \\\n",
              "gemini_thinking                      100.0          100.0       100.0   \n",
              "gemini_no_thinking                    73.3           82.9        95.3   \n",
              "deepseek_thinking                    100.0          100.0        97.5   \n",
              "deepseek_no_thinking                  93.3           97.5        97.7   \n",
              "\n",
              "                      precalculus  \n",
              "gemini_thinking             100.0  \n",
              "gemini_no_thinking           76.9  \n",
              "deepseek_thinking           100.0  \n",
              "deepseek_no_thinking        100.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Null % by subject (where GT agrees with generator):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>algebra</th>\n",
              "      <th>counting_and_probability</th>\n",
              "      <th>geometry</th>\n",
              "      <th>intermediate_algebra</th>\n",
              "      <th>number_theory</th>\n",
              "      <th>prealgebra</th>\n",
              "      <th>precalculus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gemini_thinking</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini_no_thinking</th>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_thinking</th>\n",
              "      <td>2.7</td>\n",
              "      <td>7.7</td>\n",
              "      <td>16.7</td>\n",
              "      <td>12.9</td>\n",
              "      <td>7.3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>21.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_no_thinking</th>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      algebra  counting_and_probability  geometry  \\\n",
              "gemini_thinking           0.0                       0.0       0.0   \n",
              "gemini_no_thinking        2.7                       0.0       6.7   \n",
              "deepseek_thinking         2.7                       7.7      16.7   \n",
              "deepseek_no_thinking      2.7                       0.0       6.7   \n",
              "\n",
              "                      intermediate_algebra  number_theory  prealgebra  \\\n",
              "gemini_thinking                        0.0            0.0         0.0   \n",
              "gemini_no_thinking                     3.2            0.0         0.0   \n",
              "deepseek_thinking                     12.9            7.3         7.0   \n",
              "deepseek_no_thinking                   3.2            2.4         0.0   \n",
              "\n",
              "                      precalculus  \n",
              "gemini_thinking               0.0  \n",
              "gemini_no_thinking           21.2  \n",
              "deepseek_thinking            21.2  \n",
              "deepseek_no_thinking          3.0  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "When gemini_thinking DISAGREES with generator (n=36):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cost per 1000</th>\n",
              "      <th>Agree %</th>\n",
              "      <th>Null %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gemini_thinking</th>\n",
              "      <td>$15.75</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini_no_thinking</th>\n",
              "      <td>$3.32</td>\n",
              "      <td>46.7</td>\n",
              "      <td>16.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_thinking</th>\n",
              "      <td>$0.89</td>\n",
              "      <td>54.5</td>\n",
              "      <td>38.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek_no_thinking</th>\n",
              "      <td>$0.71</td>\n",
              "      <td>52.9</td>\n",
              "      <td>5.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Cost per 1000  Agree %  Null %\n",
              "gemini_thinking             $15.75    100.0     0.0\n",
              "gemini_no_thinking           $3.32     46.7    16.7\n",
              "deepseek_thinking            $0.89     54.5    38.9\n",
              "deepseek_no_thinking         $0.71     52.9     5.6"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "if results and \"gemini_thinking\" in models:\n",
        "    reference = \"gemini_thinking\"\n",
        "    \n",
        "    usage_stats = defaultdict(lambda: {\"cost\": 0.0})\n",
        "    for r in results:\n",
        "        for model, eval_data in r[\"evaluations\"].items():\n",
        "            usage = eval_data.get(\"usage\", {})\n",
        "            usage_stats[model][\"cost\"] += usage.get(\"cost\", 0) or 0\n",
        "    \n",
        "    gt_agrees = [r for r in results \n",
        "                 if r[\"evaluations\"].get(reference, {}).get(\"answer\") == r[\"generator_answer_idx\"]]\n",
        "    gt_disagrees = [r for r in results \n",
        "                    if r[\"evaluations\"].get(reference, {}).get(\"answer\") != r[\"generator_answer_idx\"]\n",
        "                    and r[\"evaluations\"].get(reference, {}).get(\"answer\") is not None]\n",
        "    \n",
        "    def calc_agreement(subset):\n",
        "        rows = []\n",
        "        for model in models:\n",
        "            cost_per_1k = 1000 * usage_stats[model][\"cost\"] / len(results)\n",
        "            ref_not_null = [r for r in subset if r[\"evaluations\"].get(reference, {}).get(\"answer\") is not None]\n",
        "            model_nulls = sum(1 for r in ref_not_null if r[\"evaluations\"].get(model, {}).get(\"answer\") is None)\n",
        "            valid = [r for r in ref_not_null if r[\"evaluations\"].get(model, {}).get(\"answer\") is not None]\n",
        "            agree = sum(1 for r in valid \n",
        "                        if r[\"evaluations\"].get(model, {}).get(\"answer\") == \n",
        "                           r[\"evaluations\"].get(reference, {}).get(\"answer\"))\n",
        "            cond_agree_pct = agree / len(valid) if valid else 0\n",
        "            null_pct = model_nulls / len(ref_not_null) if ref_not_null else 0\n",
        "            rows.append({\"Cost per 1000\": f\"${cost_per_1k:.2f}\", \"Agree %\": cond_agree_pct, \"Null %\": null_pct})\n",
        "        df = pd.DataFrame(rows, index=models)\n",
        "        df[\"Agree %\"] = (df[\"Agree %\"] * 100).round(1)\n",
        "        df[\"Null %\"] = (df[\"Null %\"] * 100).round(1)\n",
        "        return df\n",
        "    \n",
        "    print(f\"When gemini_thinking AGREES with generator (n={len(gt_agrees)}):\")\n",
        "    display(calc_agreement(gt_agrees))\n",
        "    \n",
        "    # Breakdown by level\n",
        "    levels = sorted(set(r[\"level\"] for r in gt_agrees))\n",
        "    agree_by_level = {model: {} for model in models}\n",
        "    null_by_level = {model: {} for model in models}\n",
        "    \n",
        "    for level in levels:\n",
        "        level_subset = [r for r in gt_agrees if r[\"level\"] == level]\n",
        "        for model in models:\n",
        "            ref_not_null = [r for r in level_subset if r[\"evaluations\"].get(reference, {}).get(\"answer\") is not None]\n",
        "            model_nulls = sum(1 for r in ref_not_null if r[\"evaluations\"].get(model, {}).get(\"answer\") is None)\n",
        "            valid = [r for r in ref_not_null if r[\"evaluations\"].get(model, {}).get(\"answer\") is not None]\n",
        "            agree = sum(1 for r in valid if r[\"evaluations\"].get(model, {}).get(\"answer\") == r[\"evaluations\"].get(reference, {}).get(\"answer\"))\n",
        "            agree_by_level[model][level] = 100 * agree / len(valid) if valid else None\n",
        "            null_by_level[model][level] = 100 * model_nulls / len(ref_not_null) if ref_not_null else None\n",
        "    \n",
        "    print(\"\\nAgree % by level (where GT agrees with generator):\")\n",
        "    display(pd.DataFrame(agree_by_level).T.round(1))\n",
        "    \n",
        "    print(\"\\nNull % by level (where GT agrees with generator):\")\n",
        "    display(pd.DataFrame(null_by_level).T.round(1))\n",
        "    \n",
        "    # Breakdown by subject\n",
        "    subjects = sorted(set(r[\"subject\"] for r in gt_agrees))\n",
        "    agree_by_subject = {model: {} for model in models}\n",
        "    null_by_subject = {model: {} for model in models}\n",
        "    \n",
        "    for subject in subjects:\n",
        "        subj_subset = [r for r in gt_agrees if r[\"subject\"] == subject]\n",
        "        for model in models:\n",
        "            ref_not_null = [r for r in subj_subset if r[\"evaluations\"].get(reference, {}).get(\"answer\") is not None]\n",
        "            model_nulls = sum(1 for r in ref_not_null if r[\"evaluations\"].get(model, {}).get(\"answer\") is None)\n",
        "            valid = [r for r in ref_not_null if r[\"evaluations\"].get(model, {}).get(\"answer\") is not None]\n",
        "            agree = sum(1 for r in valid if r[\"evaluations\"].get(model, {}).get(\"answer\") == r[\"evaluations\"].get(reference, {}).get(\"answer\"))\n",
        "            agree_by_subject[model][subject] = 100 * agree / len(valid) if valid else None\n",
        "            null_by_subject[model][subject] = 100 * model_nulls / len(ref_not_null) if ref_not_null else None\n",
        "    \n",
        "    print(\"\\nAgree % by subject (where GT agrees with generator):\")\n",
        "    display(pd.DataFrame(agree_by_subject).T.round(1))\n",
        "    \n",
        "    print(\"\\nNull % by subject (where GT agrees with generator):\")\n",
        "    display(pd.DataFrame(null_by_subject).T.round(1))\n",
        "    \n",
        "    print(f\"\\nWhen gemini_thinking DISAGREES with generator (n={len(gt_disagrees)}):\")\n",
        "    display(calc_agreement(gt_disagrees))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "llm_judge_debate_NEW_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
